{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ab5e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "import httpx\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Uncomment project_color & project_hex to include them in each time entry\n",
    "\n",
    "DB = \"time_tracking.sqlite\"\n",
    "\n",
    "SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS time_entries (\n",
    "    entry_id    INTEGER PRIMARY KEY,\n",
    "    description TEXT NOT NULL,\n",
    "    project_id  INTEGER NOT NULL,\n",
    "    project_name TEXT NOT NULL,\n",
    "    seconds     INTEGER NOT NULL,\n",
    "\n",
    "    start       TEXT NOT NULL,          -- ISO-8601 in UTC (…Z)\n",
    "    stop        TEXT,                   -- ISO-8601 in UTC\n",
    "    at          TEXT NOT NULL,          -- ISO-8601 in UTC\n",
    "\n",
    "    start_ts    INTEGER NOT NULL,       -- epoch-seconds UTC\n",
    "    stop_ts     INTEGER,                -- epoch-seconds UTC\n",
    "    at_ts       INTEGER NOT NULL,       -- epoch-seconds UTC\n",
    "\n",
    "    tag_ids     TEXT,\n",
    "    tag_names   TEXT\n",
    ");\n",
    "\n",
    "CREATE INDEX IF NOT EXISTS idx_start_ts ON time_entries(start_ts);\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS entry_notes (\n",
    "    id          INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    entry_id    INTEGER NOT NULL,\n",
    "    note_text   TEXT NOT NULL,\n",
    "    created_at  TEXT NOT NULL\n",
    "                 DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ','now')),\n",
    "    FOREIGN KEY (entry_id) REFERENCES time_entries(entry_id) ON DELETE CASCADE\n",
    ");\n",
    "\n",
    "CREATE INDEX IF NOT EXISTS idx_notes_entry_id ON entry_notes(entry_id);\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def init_db():\n",
    "    with sqlite3.connect(DB) as db:\n",
    "        # Use executescript() for multiple SQL statements\n",
    "        db.executescript(SCHEMA)\n",
    "        db.commit()\n",
    "\n",
    "init_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfa5200",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime, timezone, timedelta, date\n",
    "\n",
    "def to_utc_iso_and_ts(iso_str: str) -> tuple[str, int]:\n",
    "    \"\"\"Return (ISO-8601-UTC, epoch-seconds) from any Toggl ISO string.\"\"\"\n",
    "    dt = datetime.fromisoformat(iso_str.replace(\"Z\",\"+00:00\"))\n",
    "    dt_utc = dt.astimezone(timezone.utc)\n",
    "    iso_utc = dt_utc.replace(microsecond=0).isoformat().replace(\"+00:00\",\"Z\")\n",
    "    return iso_utc, int(dt_utc.timestamp())\n",
    "\n",
    "def upsert_sqlite(entry):\n",
    "    with sqlite3.connect(DB) as db:\n",
    "        db.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO time_entries (\n",
    "                entry_id, description, project_id, project_name,\n",
    "                seconds, start, stop, at,\n",
    "                start_ts, stop_ts, at_ts,\n",
    "                tag_ids, tag_names\n",
    "            )\n",
    "            VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?)\n",
    "            ON CONFLICT(entry_id) DO UPDATE SET\n",
    "                description = excluded.description,\n",
    "                project_id  = excluded.project_id,\n",
    "                project_name= excluded.project_name,\n",
    "                seconds     = excluded.seconds,\n",
    "                start       = excluded.start,\n",
    "                stop        = excluded.stop,\n",
    "                at          = excluded.at,\n",
    "                start_ts    = excluded.start_ts,\n",
    "                stop_ts     = excluded.stop_ts,\n",
    "                at_ts       = excluded.at_ts,\n",
    "                tag_ids     = excluded.tag_ids,\n",
    "                tag_names   = excluded.tag_names;\n",
    "            \"\"\",\n",
    "            (\n",
    "                entry[\"entry_id\"],\n",
    "                entry[\"description\"],\n",
    "                entry[\"project_id\"],\n",
    "                entry[\"project_name\"],\n",
    "                entry[\"seconds\"],\n",
    "\n",
    "                entry[\"start_iso\"],   # already UTC\n",
    "                entry.get(\"stop_iso\"),\n",
    "                entry[\"at_iso\"],\n",
    "\n",
    "                entry[\"start_ts\"],\n",
    "                entry.get(\"stop_ts\"),\n",
    "                entry[\"at_ts\"],\n",
    "\n",
    "                json.dumps(entry.get(\"tag_ids\", [])),\n",
    "                json.dumps(entry.get(\"tag_names\", [])),\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7ca9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url  = f\"https://api.track.toggl.com/reports/api/v3/workspace/{os.environ[\"WORKSPACE_ID\"]}/search/time_entries\"\n",
    "auth = (os.environ[\"TOGGL_TOKEN\"], \"api_token\")\n",
    "\n",
    "tomorrow = date.today() + timedelta(days=1)\n",
    "payload = {\n",
    "    \"start_date\": \"2025-01-01\",\n",
    "    \"end_date\":   tomorrow.strftime(\"%Y-%m-%d\"),\n",
    "    \"page_size\":  100,\n",
    "    \"enrich_response\": True,\n",
    "    \"grouped\": True\n",
    "}\n",
    "data = httpx.post(url, json=payload, auth=auth).json()\n",
    "\n",
    "records = 0\n",
    "while True:\n",
    "    resp = httpx.post(url, json=payload, auth=auth, timeout=30)\n",
    "    resp.raise_for_status()                       # fail fast on errors\n",
    "    rows = resp.json()\n",
    "\n",
    "    for row in rows:\n",
    "        meta = {\n",
    "            \"project_id\":    row[\"project_id\"],\n",
    "            \"project_name\":  row.get(\"project_name\"),\n",
    "            # \"project_color\": row[\"project_color\"],\n",
    "            # \"project_hex\":   row[\"project_hex\"],\n",
    "            \"description\":   row[\"description\"],\n",
    "            \"tag_ids\":       row.get(\"tag_ids\", []),\n",
    "            \"tag_names\":     row.get(\"tag_names\", []),\n",
    "        }\n",
    "\n",
    "        # time_entries now holds 1-N actual entries for this meta combo\n",
    "        for time_entry in row[\"time_entries\"]:\n",
    "            records += 1\n",
    "\n",
    "        # during the loop …\n",
    "            start_iso, start_ts = to_utc_iso_and_ts(time_entry[\"start\"])\n",
    "            stop_iso, stop_ts   = (None, None)\n",
    "            if time_entry[\"stop\"]:\n",
    "                stop_iso, stop_ts = to_utc_iso_and_ts(time_entry[\"stop\"])\n",
    "            at_iso, at_ts = to_utc_iso_and_ts(time_entry[\"at\"])\n",
    "\n",
    "            flat = {\n",
    "                **meta,\n",
    "                \"entry_id\": time_entry[\"id\"],\n",
    "                \"start_iso\": start_iso,\n",
    "                \"stop_iso\": stop_iso,\n",
    "                \"seconds\": time_entry[\"seconds\"],\n",
    "                \"at_iso\": at_iso,\n",
    "                \"start_ts\": start_ts,\n",
    "                \"stop_ts\": stop_ts,\n",
    "                \"at_ts\": at_ts,\n",
    "            }\n",
    "            upsert_sqlite(flat)\n",
    "\n",
    "    # pagination – move to next page if the header is present\n",
    "    nxt = resp.headers.get(\"X-Next-ID\")\n",
    "    if not nxt:\n",
    "        break\n",
    "    payload[\"first_id\"] = nxt\n",
    "\n",
    "print(f\"{records=}\")\n",
    "print(f\"{tomorrow=}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
